{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between PyOpenCL, PyCUDA, Cython and NumPy\n",
    "\n",
    "@author: Adrian Oeftiger\n",
    "@date: 24.02.2017\n",
    "\n",
    "We compare a simple entry-wise sum of two large double-precision arrays for timing. The goal is to evaluate whether code maintenance is better (i.e. less lines of code, convenience) with PyOpenCL or PyCUDA + Cython while keeping an eye on timing issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pyopencl as cl\n",
    "\n",
    "from pycuda.autoinit import context\n",
    "from pycuda import gpuarray as gp\n",
    "from pycuda.elementwise import ElementwiseKernel\n",
    "from pycuda.compiler import SourceModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two arrays to be summed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_np = np.random.rand(10000000) # 10 million\n",
    "b_np = np.random.rand(10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Hardware for the Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processor\t: 0\r\n",
      "vendor_id\t: GenuineIntel\r\n",
      "cpu family\t: 6\r\n",
      "model\t\t: 45\r\n",
      "model name\t: Intel(R) Xeon(R) CPU E5-2630 0 @ 2.30GHz\r\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/cpuinfo | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:          x86_64\r\n",
      "CPU op-mode(s):        32-bit, 64-bit\r\n",
      "Byte Order:            Little Endian\r\n",
      "CPU(s):                24\r\n",
      "On-line CPU(s) list:   0-23\r\n",
      "Thread(s) per core:    2\r\n",
      "Core(s) per socket:    6\r\n",
      "Socket(s):             2\r\n",
      "NUMA node(s):          2\r\n",
      "Vendor ID:             GenuineIntel\r\n",
      "CPU family:            6\r\n",
      "Model:                 45\r\n",
      "Stepping:              7\r\n",
      "CPU MHz:               2301.000\r\n",
      "BogoMIPS:              4601.03\r\n",
      "Virtualization:        VT-x\r\n",
      "L1d cache:             32K\r\n",
      "L1i cache:             32K\r\n",
      "L2 cache:              256K\r\n",
      "L3 cache:              15360K\r\n",
      "NUMA node0 CPU(s):     0-5,12-17\r\n",
      "NUMA node1 CPU(s):     6-11,18-23\r\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla C2075 (UUID: GPU-2005e721-47ec-a062-2010-b4ccb09bdc6a)\r\n",
      "GPU 1: Tesla C2075 (UUID: GPU-18212ff0-da40-6804-5022-ab1b3950fba4)\r\n",
      "GPU 2: Tesla C2075 (UUID: GPU-38f8d367-fb09-76d6-ae39-90aeb286e83e)\r\n",
      "GPU 3: Tesla C2075 (UUID: GPU-271a5abe-433e-e72b-a9b1-855934defca8)\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... so let the testing begin!\n",
    "\n",
    "## I. NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 77.9 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 a_np + b_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython --name add_cython\n",
    "\n",
    "cimport cython\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def add(double[::1] a, double[::1] b, double[::1] r):\n",
    "    cdef int n = len(a)\n",
    "    cdef int i\n",
    "    for i in xrange(n):\n",
    "        r[i] = a[i] + b[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import add_cython\n",
    "\n",
    "r_np = np.empty_like(a_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 56.7 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "add_cython.add(a_np, b_np, r_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Check on CPU with Numpy:\n",
    "print(r_np - (a_np + b_np))\n",
    "print(np.linalg.norm(r_np - (a_np + b_np)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. PyOpenCL\n",
    "\n",
    "### first on the CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose platform:\n",
      "[0] <pyopencl.Platform 'AMD Accelerated Parallel Processing' at 0x7ff4057ca430>\n",
      "[1] <pyopencl.Platform 'NVIDIA CUDA' at 0x30b7dd0>\n",
      "Choice [0]:0\n",
      "Set the environment variable PYOPENCL_CTX='0' to avoid being asked again.\n"
     ]
    }
   ],
   "source": [
    "ctx = cl.create_some_context(interactive=True)\n",
    "queue = cl.CommandQueue(\n",
    "    ctx, properties=cl.command_queue_properties.PROFILING_ENABLE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oeftiger/anaconda/lib/python2.7/site-packages/pyopencl/cffi_cl.py:1476: CompilerWarning: Non-empty compiler output encountered. Set the environment variable PYOPENCL_COMPILER_OUTPUT=1 to see more.\n",
      "  \"to see more.\", CompilerWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation took 41.399 ms.\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "mf = cl.mem_flags\n",
    "a_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a_np)\n",
    "b_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b_np)\n",
    "\n",
    "prg = cl.Program(ctx, \"\"\"\n",
    "#pragma OPENCL EXTENSION cl_amd_fp64 : enable // (AMD)\n",
    "#pragma OPENCL EXTENSION cl_khr_fp64 : enable // (NVIDIA)\n",
    "    \n",
    "__kernel void sum(\n",
    "    __global const double *a_g, __global const double *b_g, __global double *res_g)\n",
    "{\n",
    "  int gid = get_global_id(0);\n",
    "  res_g[gid] = a_g[gid] + b_g[gid];\n",
    "}\n",
    "\"\"\").build()\n",
    "\n",
    "res_g = cl.Buffer(ctx, mf.WRITE_ONLY, a_np.nbytes)\n",
    "\n",
    "event = prg.sum(queue, a_np.shape, None, a_g, b_g, res_g)\n",
    "event.wait()\n",
    "\n",
    "print ('Computation took {:.3f} ms.'.format(\n",
    "    1e-6*(event.profile.end - event.profile.start)))\n",
    "\n",
    "res_np = np.empty_like(a_np)\n",
    "cl.enqueue_copy(queue, res_np, res_g)\n",
    "\n",
    "# Check on CPU with Numpy:\n",
    "print(res_np - (a_np + b_np))\n",
    "print(np.linalg.norm(res_np - (a_np + b_np)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose platform:\n",
      "[0] <pyopencl.Platform 'AMD Accelerated Parallel Processing' at 0x7ff4057ca430>\n",
      "[1] <pyopencl.Platform 'NVIDIA CUDA' at 0x30b7dd0>\n",
      "Choice [0]:1\n",
      "Choose device(s):\n",
      "[0] <pyopencl.Device 'Tesla C2075' on 'NVIDIA CUDA' at 0x30b7eb0>\n",
      "[1] <pyopencl.Device 'Tesla C2075' on 'NVIDIA CUDA' at 0x30b7f40>\n",
      "[2] <pyopencl.Device 'Tesla C2075' on 'NVIDIA CUDA' at 0x30b7fd0>\n",
      "[3] <pyopencl.Device 'Tesla C2075' on 'NVIDIA CUDA' at 0x30b8060>\n",
      "Choice, comma-separated [0]:1\n",
      "Set the environment variable PYOPENCL_CTX='1:1' to avoid being asked again.\n"
     ]
    }
   ],
   "source": [
    "ctx = cl.create_some_context(interactive=True)\n",
    "queue = cl.CommandQueue(\n",
    "    ctx, properties=cl.command_queue_properties.PROFILING_ENABLE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation took 2.553 ms.\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "mf = cl.mem_flags\n",
    "a_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a_np)\n",
    "b_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b_np)\n",
    "\n",
    "prg = cl.Program(ctx, \"\"\"\n",
    "#pragma OPENCL EXTENSION cl_amd_fp64 : enable // (AMD)\n",
    "#pragma OPENCL EXTENSION cl_khr_fp64 : enable // (NVIDIA)\n",
    "    \n",
    "__kernel void sum(\n",
    "    __global const double *a_g, __global const double *b_g, __global double *res_g)\n",
    "{\n",
    "  int gid = get_global_id(0);\n",
    "  res_g[gid] = a_g[gid] + b_g[gid];\n",
    "}\n",
    "\"\"\").build()\n",
    "\n",
    "res_g = cl.Buffer(ctx, mf.WRITE_ONLY, a_np.nbytes)\n",
    "\n",
    "event = prg.sum(queue, a_np.shape, None, a_g, b_g, res_g)\n",
    "event.wait()\n",
    "\n",
    "print ('Computation took {:.3f} ms.'.format(\n",
    "    1e-6*(event.profile.end - event.profile.start)))\n",
    "\n",
    "res_np = np.empty_like(a_np)\n",
    "cl.enqueue_copy(queue, res_np, res_g)\n",
    "\n",
    "# Check on CPU with Numpy:\n",
    "print(res_np - (a_np + b_np))\n",
    "print(np.linalg.norm(res_np - (a_np + b_np)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. PyCUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_pyc, b_pyc = gp.to_gpu(a_np), gp.to_gpu(b_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple GPUArray adding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 72.78 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 3: 4.47 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "global r_pyc\n",
    "r_pyc = a_pyc + b_pyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Check on CPU with Numpy:\n",
    "print(r_pyc.get() - (a_np + b_np))\n",
    "print(np.linalg.norm(r_pyc.get() - (a_np + b_np)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With an ElementwiseKernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add = ElementwiseKernel(\n",
    "    'double* a, double* b, double* r',\n",
    "    'r[i] = a[i] + b[i];'\n",
    ")\n",
    "\n",
    "r_pyc = gp.empty_like(a_pyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 112.97 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 3: 3.02 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "add(a_pyc, b_pyc, r_pyc)\n",
    "context.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Check on CPU with Numpy:\n",
    "print(r_pyc.get() - (a_np + b_np))\n",
    "print(np.linalg.norm(r_pyc.get() - (a_np + b_np)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And finally with a SourceModule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod = SourceModule('''\n",
    "__global__ void add(int n, double* a, double* b, double* r) {\n",
    "    for (int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "             i < n;\n",
    "             i += blockDim.x * gridDim.x) {\n",
    "        r[i] = a[i] + b[i];\n",
    "    }\n",
    "}\n",
    "''')\n",
    "\n",
    "add_sm = mod.get_function('add')\n",
    "\n",
    "add_sm.prepare('iPPP')\n",
    "\n",
    "def idivup(a, b):\n",
    "    ''' Compute int(a)//int(b) and round up to next integer if a%b != 0 '''\n",
    "    a = np.int32(a)\n",
    "    b = np.int32(b)\n",
    "    z = (a // b + 1) if (a % b != 0) else (a // b)\n",
    "    return int(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 2.64 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "add_sm.prepared_call(\n",
    "    # grid, block:\n",
    "    (idivup(len(a_np), 256), 1, 1), (256, 1, 1),\n",
    "    # in- and outputs:\n",
    "    np.int32(len(a_np)), a_pyc.gpudata, b_pyc.gpudata, r_pyc.gpudata\n",
    ")\n",
    "context.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Check on CPU with Numpy:\n",
    "print(r_pyc.get() - (a_np + b_np))\n",
    "print(np.linalg.norm(r_pyc.get() - (a_np + b_np)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Results:\n",
    "\n",
    "- CPU NumPy: 77.9ms\n",
    "- CPU Cython: 56.7ms\n",
    "- CPU PyOpenCL: 41.4ms\n",
    "- GPU PyOpenCL: 2.6ms\n",
    "- GPU PyCUDA GPUArray: 4.5ms\n",
    "- GPU PyCUDA ElementwiseKernel: 3ms\n",
    "- GPU PyCUDA SourceModule: 2.6ms\n",
    "\n",
    "On the GPU, both PyOpenCL and PyCUDA (with its `SourceModule`) yield the same timing results. Any abstraction provided by PyCUDA (the `ElementwiseKernel` and the `GPUArray` direct summing) slows down the performance. PyOpenCL introduces more \"clutter\" in terms of object handling compared to PyCUDA but opens the chance to run on the CPU as well, using the same source code!\n",
    "\n",
    "On the CPU, PyOpenCL accelerates close to a factor 2 in comparison to NumPy, while Cython accelerates by a factor 1.4. Hence, PyOpenCL is even the best choice in this case.\n",
    "\n",
    "### So, all in all...\n",
    "...even for the present simple summation example, PyOpenCL provides a viable choice to reduce the total amount of code to be handled for GPU and CPU (~30 lines of PyOpenCL vs. 17 lines with Cython + 25 with PyCUDA)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
